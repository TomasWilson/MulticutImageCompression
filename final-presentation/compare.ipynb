{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from ignite.metrics import SSIM\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ssim(baseline_image, images):\n",
    "    \"\"\"\n",
    "    Compute SSIM scores between a baseline image and a batch of images.\n",
    "\n",
    "    Args:\n",
    "        baseline_image (ndarray): A single baseline image of shape (H, W, 3).\n",
    "        images (ndarray): A batch of images of shape (B, H, W, 3).\n",
    "\n",
    "    Returns:\n",
    "        ndarray: An array of shape (B,) containing SSIM scores.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure inputs are numpy arrays\n",
    "    baseline_image = np.asarray(baseline_image)\n",
    "    images = np.asarray(images)\n",
    "\n",
    "    try:\n",
    "        # Convert to torch tensors and move to CUDA\n",
    "        baseline_tensor = torch.from_numpy(baseline_image).permute(2, 0, 1).unsqueeze(0).float().cuda() / 255.0\n",
    "        images_tensor = torch.from_numpy(images).permute(0, 3, 1, 2).float().cuda() / 255.0\n",
    "\n",
    "        # Initialize SSIM metric\n",
    "        ssim_metric = SSIM(data_range=1.0)\n",
    "\n",
    "        # Compute SSIM scores\n",
    "        ssim_scores = []\n",
    "        for img in images_tensor:\n",
    "            img = img.unsqueeze(0)  # Add batch dimension\n",
    "            ssim_metric.update((img, baseline_tensor))\n",
    "            ssim_score = ssim_metric.compute()\n",
    "            ssim_scores.append(ssim_score)  # Convert to Python float\n",
    "            ssim_metric.reset()\n",
    "\n",
    "        return np.array(ssim_scores)\n",
    "    finally:\n",
    "        # Explicitly delete tensors and clear GPU memory\n",
    "        del baseline_tensor, images_tensor, ssim_metric\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ssim_table(base_img_path: Path, compressed_imgs: list, compression_levels: list, compressed_img_sizes: list):\n",
    "    category = base_img_path.parent.name\n",
    "    name = base_img_path.name\n",
    "    base_img = cv2.imread(str(base_img_path), cv2.IMREAD_COLOR)\n",
    "\n",
    "    data = dict()\n",
    "    data[\"category\"] = [category for _ in range(len(compressed_imgs))]\n",
    "    data[\"name\"] = [name for _ in range(len(compressed_imgs))]\n",
    "    data[\"level\"] = compression_levels\n",
    "    data[\"size\"] = compressed_img_sizes\n",
    "    data[\"ssim\"] = list(compute_ssim(base_img, np.array(compressed_imgs)))\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_uncompressed(p: Path):\n",
    "    category = p.parent.name\n",
    "    level = int(p.parent.parent.name)\n",
    "    bits = int(p.stem.split(\"###\")[0])\n",
    "    key = p.name.split(\"###\")[1]\n",
    "    loc = Path(\"../data/splitimages/test\") / category / key\n",
    "    assert loc.exists()\n",
    "    return bits, level, loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def load_multicut_images():\n",
    "    data = defaultdict(lambda: [[], [], []]) # key -> \n",
    "    ROOT = Path(\"samples/multicut\")\n",
    "\n",
    "    for category in ROOT.glob(\"*\"):\n",
    "        if not category.is_dir(): continue\n",
    "        for img_p in category.glob(\"**/*.png\"):\n",
    "            bits, level, location = find_uncompressed(img_p)\n",
    "\n",
    "            data[str(location)][0].append(bits)\n",
    "            data[str(location)][1].append(level)\n",
    "            data[str(location)][2].append(img_p)\n",
    "    \n",
    "    return data\n",
    "\n",
    "mc_img_data = load_multicut_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs = []\n",
    "# for key_path, (bits, levels, compressed_img_paths) in tqdm(mc_img_data.items()):\n",
    "#     uncompressed_img = cv2.imread(key_path, cv2.IMREAD_COLOR)\n",
    "#     dfs.append(make_ssim_table(Path(key_path), [cv2.imread(str(i), cv2.IMREAD_COLOR) for i in compressed_img_paths], levels, bits))\n",
    "\n",
    "# df = pd.concat(dfs)\n",
    "# df.to_csv(\"data-multicut.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def jpeg_compress(img, q):\n",
    "#     res, data = cv2.imencode(\".jpg\", img, [cv2.IMWRITE_JPEG_QUALITY, q])\n",
    "#     assert res\n",
    "#     decoded_img = cv2.imdecode(data, cv2.IMREAD_COLOR)\n",
    "#     return len(data) * 8, decoded_img\n",
    "\n",
    "# ROOT = Path(\"../data/splitimages/test\")\n",
    "# JPEG_QUALITIES = [1] + list(range(5, 101, 5))\n",
    "\n",
    "# dfs = []\n",
    "\n",
    "# for category in ROOT.glob(\"*\"):\n",
    "#     if not category.is_dir(): continue\n",
    "#     for img_p in tqdm(list(category.glob(\"*.png\"))):\n",
    "#         img = cv2.imread(str(img_p), cv2.IMREAD_COLOR)\n",
    "\n",
    "\n",
    "#         sizes = []\n",
    "#         imgs = []\n",
    "\n",
    "\n",
    "#         for q in JPEG_QUALITIES:\n",
    "#             compressed_size, compressed = jpeg_compress(img, q)\n",
    "#             sizes.append(compressed_size)\n",
    "#             imgs.append(compressed)\n",
    "\n",
    "#         dfs.append(make_ssim_table(img_p, imgs, JPEG_QUALITIES, sizes))\n",
    "\n",
    "# df = pd.concat(dfs)\n",
    "# df.to_csv(\"data-jpeg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def jpeg2000_compress(img, q):\n",
    "#     res, data = cv2.imencode(\".jp2\", img, [cv2.IMWRITE_JPEG2000_COMPRESSION_X1000, q])\n",
    "#     assert res\n",
    "#     decoded_img = cv2.imdecode(data, cv2.IMREAD_COLOR)\n",
    "#     return len(data) * 8, decoded_img\n",
    "\n",
    "# ROOT = Path(\"../data/splitimages/test\")\n",
    "# JPEG_2000_QUALITIES = [1] + list(range(50, 1001, 50))\n",
    "\n",
    "# dfs = []\n",
    "\n",
    "# for category in ROOT.glob(\"*\"):\n",
    "#     if not category.is_dir(): continue\n",
    "\n",
    "#     for img_p in tqdm(list(category.glob(\"*.png\"))):\n",
    "#         img = cv2.imread(str(img_p), cv2.IMREAD_COLOR)\n",
    "\n",
    "#         sizes = []\n",
    "#         imgs = []\n",
    "\n",
    "#         try:\n",
    "#             for q in JPEG_2000_QUALITIES:\n",
    "#                 compressed_size, compressed = jpeg2000_compress(img, q)\n",
    "#                 sizes.append(compressed_size)\n",
    "#                 imgs.append(compressed)\n",
    "\n",
    "#             dfs.append(make_ssim_table(img_p, imgs, JPEG_2000_QUALITIES, sizes))\n",
    "#         except:\n",
    "#             print(\"Failure for file: \", str(img_p))\n",
    "\n",
    "# df = pd.concat(dfs)\n",
    "# df.to_csv(\"data-jpeg2000.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# def webp_compress(img, q):\n",
    "#     res, data = cv2.imencode(\".webp\", img, [cv2.IMWRITE_WEBP_QUALITY, q])\n",
    "#     assert res\n",
    "#     decoded_img = cv2.imdecode(data, cv2.IMREAD_COLOR)\n",
    "#     return len(data) * 8, decoded_img\n",
    "\n",
    "\n",
    "# ROOT = Path(\"../data/splitimages/test\")\n",
    "# WEBP_QUALS = [1] + list(range(5, 101, 5))\n",
    "\n",
    "# dfs = []\n",
    "\n",
    "# for category in ROOT.glob(\"*\"):\n",
    "#     if not category.is_dir(): continue\n",
    "\n",
    "#     for img_p in tqdm(list(category.glob(\"*.png\"))):\n",
    "#         img = cv2.imread(str(img_p), cv2.IMREAD_COLOR)\n",
    "\n",
    "#         sizes = []\n",
    "#         imgs = []\n",
    "\n",
    "#         try:\n",
    "#             for q in WEBP_QUALS:\n",
    "#                 compressed_size, compressed = webp_compress(img, q)\n",
    "#                 sizes.append(compressed_size)\n",
    "#                 imgs.append(compressed)\n",
    "\n",
    "#             dfs.append(make_ssim_table(img_p, imgs, WEBP_QUALS, sizes))\n",
    "#         except:\n",
    "#             print(\"Failure for file: \", str(img_p))\n",
    "\n",
    "# df = pd.concat(dfs)\n",
    "# df.to_csv(\"data-webp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [02:55<00:00,  2.75s/it]\n",
      "100%|██████████| 64/64 [01:27<00:00,  1.37s/it]\n",
      "100%|██████████| 8/8 [00:41<00:00,  5.22s/it]\n",
      "100%|██████████| 30/30 [05:12<00:00, 10.41s/it]\n",
      "100%|██████████| 15/15 [02:21<00:00,  9.41s/it]\n",
      " 32%|███▏      | 18/57 [02:57<02:47,  4.29s/it]"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import numpy as np\n",
    "from pillow_heif import register_heif_opener\n",
    "from PIL import Image\n",
    "register_heif_opener()\n",
    "\n",
    "def heif_compress(img, q):\n",
    "    # Convert OpenCV image (numpy array) to PIL Image\n",
    "    img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # Save the image as HEIC in memory\n",
    "    img_bytes = io.BytesIO()\n",
    "    img_pil.save(img_bytes, format=\"HEIF\", quality=q)\n",
    "    \n",
    "    # Get the size of the encoded image in bits\n",
    "    bit_size = len(img_bytes.getvalue()) * 8\n",
    "    \n",
    "    # Decode the HEIC image back to OpenCV format\n",
    "    img_bytes.seek(0)\n",
    "    decoded_pil = Image.open(img_bytes)\n",
    "    decoded_img = cv2.cvtColor(np.array(decoded_pil), cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    return bit_size, decoded_img\n",
    "\n",
    "ROOT = Path(\"../data/splitimages/test\")\n",
    "HEIC_QUALS = [1] + list(range(5, 101, 5))\n",
    "dfs = []\n",
    "\n",
    "for category in ROOT.glob(\"*\"):\n",
    "    if not category.is_dir(): continue\n",
    "\n",
    "    for img_p in tqdm(list(category.glob(\"*.png\"))):\n",
    "        img = cv2.imread(str(img_p), cv2.IMREAD_COLOR)\n",
    "\n",
    "        sizes = []\n",
    "        imgs = []\n",
    "        try:\n",
    "            for q in HEIC_QUALS:\n",
    "                compressed_size, compressed = heif_compress(img, q)\n",
    "                sizes.append(compressed_size)\n",
    "                imgs.append(compressed)\n",
    "\n",
    "            dfs.append(make_ssim_table(img_p, imgs, HEIC_QUALS, sizes))\n",
    "        except:\n",
    "            print(\"Failure for file: \", str(img_p))\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "df.to_csv(\"data-heif.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
